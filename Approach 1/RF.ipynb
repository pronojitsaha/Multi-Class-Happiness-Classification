{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports libraries\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "from numpy.random import seed\n",
    "#from scipy.special import cbrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from scipy.stats import rankdata\n",
    "%matplotlib inline\n",
    "\n",
    "# reproduce results\n",
    "seed(584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10357, 18), (3387, 17))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_FBFog7d.csv')\n",
    "test = pd.read_csv('data/Test_L4P23N3.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13744, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the additional variable provided\n",
    "alcohol = pd.read_csv('data/NewVariable_Alcohol.csv')\n",
    "alcohol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10357, 19), (3387, 18))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(alcohol, on='ID')\n",
    "test = test.merge(alcohol, on='ID')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_vars = ['Var1', 'WorkStatus', 'Divorce', 'Widowed', 'Residence_Region', 'income', 'Engagement_Religion', \n",
    "                    u'babies', u'preteen', u'teens', 'Var2', 'Gender', 'Unemployed10', 'Alcohol_Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding some of the categorical vars to capture information in their ordering\n",
    "number = preprocessing.LabelEncoder()\n",
    "for var in ['WorkStatus', 'Residence_Region', 'income', 'Engagement_Religion', 'Alcohol_Consumption']:\n",
    "    train[var+'_encoded'] = number.fit_transform(train[var].astype('str'))\n",
    "    test[var+'_encoded'] = number.fit_transform(test[var].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_vars = [u'Education', u'TVhours', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removing outliers as per standard deviation\n",
    "train.ix[train['babies'] >= 3, 'babies'] = 3\n",
    "test.ix[test['babies'] >= 3, 'babies'] = 3\n",
    "\n",
    "train.ix[train['preteen'] >= 4, 'preteen'] = 4\n",
    "test.ix[test['babies'] >= 4, 'preteen'] = 4\n",
    "\n",
    "train.ix[train['teens'] >= 3, 'teens'] = 3\n",
    "test.ix[test['teens'] >= 3, 'teens'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('removing outliers in ', u'TVhours', ':\\n', 668     24\n",
      "1884    22\n",
      "1949    22\n",
      "2261    24\n",
      "3382    20\n",
      "4033    20\n",
      "4207    20\n",
      "4734    20\n",
      "5521    24\n",
      "5556    20\n",
      "6046    24\n",
      "6409    21\n",
      "7251    24\n",
      "7732    20\n",
      "Name: TVhours, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#removing outliers\n",
    "outlier_cutoff = 7\n",
    "for feature in numeric_vars:\n",
    "    train[feature + '_std'] = np.abs( (train[feature] - train[feature].mean()) / train[feature].std() )\n",
    "    if len( train.ix[ train[ feature + '_std' ] > outlier_cutoff, feature ] ) > 0:\n",
    "        print('removing outliers in ', feature, ':\\n', train.loc[ train[ feature + '_std' ] > outlier_cutoff, feature ])\n",
    "        #train.loc[ train[feature + '_std'] > outlier_cutoff, feature ] = np.nan\n",
    "    train.drop( [feature + '_std'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('removing outliers in ', u'TVhours', ':\\n', 1484    21\n",
      "1963    20\n",
      "2019    20\n",
      "2762    20\n",
      "Name: TVhours, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#removing outliers in test set\n",
    "outlier_cutoff = 7\n",
    "for feature in numeric_vars:\n",
    "    test[feature + '_std'] = np.abs( (test[feature] - test[feature].mean()) / test[feature].std() )\n",
    "    if len( test.ix[ test[ feature + '_std' ] > outlier_cutoff, feature ] ) > 0:\n",
    "        print('removing outliers in ', feature, ':\\n', test.loc[ test[ feature + '_std' ] > outlier_cutoff, feature ])\n",
    "        test.ix[ test[feature + '_std'] > outlier_cutoff, feature ] = np.nan\n",
    "    test.drop( [feature + '_std'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pretty Happy    5916\n",
       "Very Happy      3146\n",
       "Not Happy       1295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Happy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train= train.fillna(-999)\n",
    "test = test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train.copy()\n",
    "\n",
    "label = data['Happy'].map({'Very Happy': 2, 'Pretty Happy': 1, 'Not Happy': 0})\n",
    "\n",
    "dropCols = ['ID', 'Happy', 'Gender']\n",
    "data.drop(dropCols, axis=1, inplace = True)\n",
    "\n",
    "y = label\n",
    "X = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(labels=[1 1 0 ..., 1 0 0], n_iter=1, test_size=0.25, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_fold = StratifiedShuffleSplit(y, n_iter=1, test_size=0.25, random_state=0)\n",
    "holdout_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7767, 77), (2590, 77), (7767,), (2590,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, holdout_index in holdout_fold:\n",
    "    X_train, X_test = X.ix[train_index], X.ix[holdout_index]\n",
    "    y_train, y_test = y[train_index], y[holdout_index]\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 0.5, 2: 0.5},\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=True, random_state=584, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=4,\n",
       "       param_grid={'n_estimators': [200, 400, 600], 'max_depth': [5, 7, 9], 'min_samples_leaf': [1, 3, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the best parameters for RF using GridSearchCV\n",
    "from sklearn import grid_search\n",
    "rf = RandomForestClassifier(class_weight={0:1, 1:.5, 2:.5}, criterion = 'gini', oob_score=True, bootstrap = True, n_jobs=-1, random_state=584) \n",
    "parameters = {'n_estimators':[200, 400, 600], 'max_depth':[5, 7, 9], 'min_samples_leaf':[1,3,6]}\n",
    "clf_grid = grid_search.GridSearchCV(rf, parameters, cv=4, n_jobs=4)\n",
    "clf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'min_samples_leaf': 3, 'n_estimators': 400}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_best = clf_grid.best_estimator_\n",
    "pred_ytest = rf_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature Alcohol_Consumption_Multiple times in a week (0.223666)\n",
      "2. feature Alcohol_Consumption_encoded (0.207017)\n",
      "3. feature Alcohol_Consumption_-999 (0.138649)\n",
      "4. feature Divorce_-999 (0.034578)\n",
      "5. feature Score (0.025290)\n",
      "6. feature Alcohol_Consumption_Rarely (0.023490)\n",
      "7. feature Alcohol_Consumption_Never (0.023412)\n",
      "8. feature Education (0.021066)\n",
      "9. feature Divorce_no (0.017663)\n",
      "10. feature Alcohol_Consumption_Occassional (0.015320)\n",
      "11. feature TVhours (0.015151)\n",
      "12. feature income_encoded (0.014058)\n",
      "13. feature Engagement_Religion_encoded (0.013879)\n",
      "14. feature Alcohol_Consumption_2 - 3 times a month (0.013760)\n",
      "15. feature WorkStatus_encoded (0.012833)\n",
      "16. feature Residence_Region_encoded (0.012232)\n",
      "17. feature income_$25000 or more (0.012000)\n",
      "18. feature Widowed_-999 (0.010740)\n",
      "19. feature Unemployed10 (0.009937)\n",
      "20. feature Var2 (0.009210)\n"
     ]
    }
   ],
   "source": [
    "importances = rf_best.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_best.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(20):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2253\n",
       "0     307\n",
       "2      30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting probabilities\n",
    "X_test['prediction'] = np.argmax(pred_ytest.reshape( y_test.shape[0], 3 ), axis=1)\n",
    "X_test['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 237,   42,   28],\n",
       "       [  87, 1428,  738],\n",
       "       [   0,    9,   21]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(X_test['prediction'],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7085714285714285"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the evaluation metric\n",
    "score = 0\n",
    "points = []\n",
    "for (predicted, true) in zip(X_test['prediction'].astype(str).map({'2':15, '1': 10, '0': 5}), \n",
    "                             y_test.astype(str).map({'2':15, '1': 10, '0': 5})):\n",
    "    points.append(true - predicted)\n",
    "X_test['Point'] = points\n",
    "X_test['Score'] = X_test['Point'].astype(str).map({'0':50, '5':10 ,'10':5, '-5':-5, '-10':-10}) \n",
    "X_test['Score'].sum()/float((len(y_test)*50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the predictions for ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class0 = [var[0] for var in pred_ytest.reshape( y_test.shape[0], 3 )]\n",
    "pred_class1 = [var[1] for var in pred_ytest.reshape( y_test.shape[0], 3 )]\n",
    "pred_class2 = [var[2] for var in pred_ytest.reshape( y_test.shape[0], 3 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_sub = pd.DataFrame({ 'ID': train.ix[holdout_index,'ID'], 'class0':pred_class0, 'class1':pred_class1, 'class2':pred_class2})\n",
    "hold_sub.to_csv('data/rf_hold_sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For test\n",
    "test2 = test.copy()\n",
    "testdropcols = list(set(dropCols)-set(['Happy']))\n",
    "test2 = test2.drop(testdropcols, axis=1)\n",
    "\n",
    "for var in test2.columns:\n",
    "    new = list(set(test2[var]) - set(train[var]))\n",
    "    test2.ix[test2[var].isin(new), var] = np.nan\n",
    "\n",
    "final_test = pd.get_dummies(test2)\n",
    "missingCols = list(set(X.columns)-set(final_test.columns))\n",
    "for col in missingCols:\n",
    "    final_test[col] = 0\n",
    "final_test = final_test[X.columns]\n",
    "assert X.columns.equals(final_test.columns)\n",
    "final_test = final_test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_full = RandomForestClassifier(n_estimators=400, max_depth=9, criterion = 'gini', min_samples_split=2, \n",
    "                             min_samples_leaf=3, class_weight={0:1, 1:.5, 2:.5}, oob_score=True, bootstrap = True, n_jobs=-1, random_state=584)\n",
    "clf_full.fit(X, y)\n",
    "pred_finaltest = clf_full.predict_proba(final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving final test predictions for ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_class0 = [var[0] for var in pred_finaltest.reshape( final_test.shape[0], 3 )]\n",
    "final_class1 = [var[1] for var in pred_finaltest.reshape( final_test.shape[0], 3 )]\n",
    "final_class2 = [var[2] for var in pred_finaltest.reshape( final_test.shape[0], 3 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID': test['ID'], 'class0':final_class0, 'class1':final_class1, 'class2':final_class2})\n",
    "sub.to_csv('data/rf_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
