{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# suppress pandas warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = RuntimeWarning)\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "\n",
    "# imports\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "from numpy.random import seed\n",
    "#from scipy.special import cbrt\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from scipy.stats import rankdata\n",
    "import cPickle\n",
    "%matplotlib inline\n",
    "\n",
    "# reproduce results\n",
    "seed(584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10357, 18), (3387, 17))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_FBFog7d.csv')\n",
    "test = pd.read_csv('data/Test_L4P23N3.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13744, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol = pd.read_csv('data/NewVariable_Alcohol.csv')\n",
    "alcohol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10357, 19), (3387, 18))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(alcohol, on='ID')\n",
    "test = test.merge(alcohol, on='ID')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_vars = ['Var1', 'WorkStatus', 'Divorce', 'Widowed', 'Residence_Region', 'income', 'Engagement_Religion', \n",
    "                    'babies', 'preteen', 'teens', 'Var2', 'Gender', 'Unemployed10', 'Alcohol_Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_vars = ['Education', 'TVhours', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging rare levels\n",
    "train.ix[train['babies'] >= 3, 'babies'] = 3\n",
    "test.ix[test['babies'] >= 3, 'babies'] = 3\n",
    "\n",
    "train.ix[train['preteen'] >= 4, 'preteen'] = 4\n",
    "test.ix[test['babies'] >= 4, 'preteen'] = 4\n",
    "\n",
    "train.ix[train['teens'] >= 3, 'teens'] = 3\n",
    "test.ix[test['teens'] >= 3, 'teens'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('removing outliers in ', 'TVhours', ':\\n', 668     24\n",
      "1884    22\n",
      "1949    22\n",
      "2261    24\n",
      "3382    20\n",
      "4033    20\n",
      "4207    20\n",
      "4734    20\n",
      "5521    24\n",
      "5556    20\n",
      "6046    24\n",
      "6409    21\n",
      "7251    24\n",
      "7732    20\n",
      "Name: TVhours, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#removing outliers\n",
    "outlier_cutoff = 7\n",
    "for feature in numeric_vars:\n",
    "    train[feature + '_std'] = np.abs( (train[feature] - train[feature].mean()) / train[feature].std() )\n",
    "    if len( train.ix[ train[ feature + '_std' ] > outlier_cutoff, feature ] ) > 0:\n",
    "        print('removing outliers in ', feature, ':\\n', train.loc[ train[ feature + '_std' ] > outlier_cutoff, feature ])\n",
    "        train.ix[ train[feature + '_std'] > outlier_cutoff, feature ] = np.nan\n",
    "    train.drop( [feature + '_std'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('removing outliers in ', 'TVhours', ':\\n', 1484    21\n",
      "1963    20\n",
      "2019    20\n",
      "2762    20\n",
      "Name: TVhours, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "#removing outliers\n",
    "outlier_cutoff = 7\n",
    "for feature in numeric_vars:\n",
    "    test[feature + '_std'] = np.abs( (test[feature] - test[feature].mean()) / test[feature].std() )\n",
    "    if len( test.ix[ test[ feature + '_std' ] > outlier_cutoff, feature ] ) > 0:\n",
    "        print('removing outliers in ', feature, ':\\n', test.loc[ test[ feature + '_std' ] > outlier_cutoff, feature ])\n",
    "        test.ix[ test[feature + '_std'] > outlier_cutoff, feature ] = np.nan\n",
    "    test.drop( [feature + '_std'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = preprocessing.LabelEncoder()\n",
    "for var in ['WorkStatus', 'Residence_Region', 'income', 'Engagement_Religion', 'Alcohol_Consumption','TVhours', 'Score']:\n",
    "    train[var+'_encoded'] = number.fit_transform(train[var].astype('str'))\n",
    "    test[var+'_encoded'] = number.fit_transform(test[var].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pretty Happy    5916\n",
       "Very Happy      3146\n",
       "Not Happy       1295\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Happy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train= train.fillna(-999)\n",
    "test = test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = train.copy()\n",
    "\n",
    "label = data['Happy'].map({'Very Happy': 2, 'Pretty Happy': 1, 'Not Happy': 0})\n",
    "\n",
    "dropCols = ['ID', 'Happy']\n",
    "data.drop(dropCols, axis=1, inplace = True)\n",
    "\n",
    "y = label\n",
    "X = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(labels=[1 1 0 ..., 1 0 0], n_iter=1, test_size=0.25, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_fold = StratifiedShuffleSplit(y, n_iter=1, test_size=0.25, random_state=0)\n",
    "holdout_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7767, 80), (2590, 80), (7767,), (2590,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, holdout_index in holdout_fold:\n",
    "    X_train, X_test = X.ix[train_index], X.ix[holdout_index]\n",
    "    y_train, y_test = y[train_index], y[holdout_index]\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [2 if data == 0 else 0.5 if data == 1 else 0.5 for data in y_train] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['xgb1','xgb2','xgb3','xgb4','xgb5']\n",
    "predictions = pd.DataFrame(index=X_test.index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rounds = [100,300,500,800,1200]\n",
    "etas = [0.003,0.01,0.03,0.1,0.5]\n",
    "seeds = [584,585,586,587,588]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (i,j,k,col) in zip(rounds,etas,seeds,columns):\n",
    "    #XGB1\n",
    "    #tuning the other parameters\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multi:softprob\"\n",
    "    #To avoid overfitting: The first way is to directly control model complexity\n",
    "    params[\"min_child_weight\"] = 6 #The larger, the more conservative the algorithm will be.\n",
    "    params[\"max_depth\"] = 5\n",
    "    #params[\"gamma\"] = 10 #The larger, the more conservative the algorithm will be.\n",
    "    params[\"eta\"] = j #higher is more conservative [0,1], if reduced then increase num_rounds\n",
    "    #The second way is to add randomness to make training robust to noise\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "\n",
    "    #Handle Imbalanced Dataset\n",
    "    #If you care only about the ranking order (AUC) of your prediction\n",
    "    #params[\"scale_pos_weight\"] = 1 #ratio of labels in target variable\n",
    "    #params[\"eval_metric \"] = 'mlogloss'\n",
    "    #If you care about predicting the right probability\n",
    "    #params[\"max_delta_step\"]= 10 #should be high for skewed data\n",
    "\n",
    "    params[\"seed\"] = k\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"nthread\"] = 16\n",
    "    params[\"num_class\"] = 3\n",
    "    plst = list(params.items())\n",
    "    num_rounds = i\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X_train, label=y_train, weight = weights, missing = -999)\n",
    "    xgtest = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    pred_ytest = model.predict(xgtest)\n",
    "    predictions[col] = np.argmax(pred_ytest.reshape( y_test.shape[0], 3 ), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions['y_test'] = y_test\n",
    "predictions.to_csv('data/xgb_hold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For test\n",
    "test2 = test.copy()\n",
    "testdropcols = list(set(dropCols)-set(['Happy']))\n",
    "test2 = test2.drop(testdropcols, axis=1)\n",
    "\n",
    "for var in test2.columns:\n",
    "    new = list(set(test2[var]) - set(train[var]))\n",
    "    test2.ix[test2[var].isin(new), var] = np.nan\n",
    "\n",
    "final_test = pd.get_dummies(test2)\n",
    "missingCols = list(set(X.columns)-set(final_test.columns))\n",
    "for col in missingCols:\n",
    "    final_test[col] = 0\n",
    "final_test = final_test[X.columns]\n",
    "assert X.columns.equals(final_test.columns)\n",
    "final_test = final_test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_test = [2 if data == 0 else 0.5 if data == 1 else 0.5 for data in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_final = pd.DataFrame(index=final_test.index, columns=columns)\n",
    "for (i,j,k,col) in zip(rounds,etas,seeds,columns):\n",
    "    #XGB1\n",
    "    #tuning the other parameters\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"multi:softprob\"\n",
    "    #To avoid overfitting: The first way is to directly control model complexity\n",
    "    params[\"min_child_weight\"] = 6 #The larger, the more conservative the algorithm will be.\n",
    "    params[\"max_depth\"] = 5\n",
    "    #params[\"gamma\"] = 10 #The larger, the more conservative the algorithm will be.\n",
    "    params[\"eta\"] = j #higher is more conservative [0,1], if reduced then increase num_rounds\n",
    "    #The second way is to add randomness to make training robust to noise\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "\n",
    "    #Handle Imbalanced Dataset\n",
    "    #If you care only about the ranking order (AUC) of your prediction\n",
    "    #params[\"scale_pos_weight\"] = 1 #ratio of labels in target variable\n",
    "    #params[\"eval_metric \"] = 'mlogloss'\n",
    "    #If you care about predicting the right probability\n",
    "    #params[\"max_delta_step\"]= 10 #should be high for skewed data\n",
    "\n",
    "    params[\"seed\"] = k\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"nthread\"] = 4\n",
    "    params[\"num_class\"] = 3\n",
    "    plst = list(params.items())\n",
    "    num_rounds = i\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X, label=y, weight = weight_test, missing = -999)\n",
    "    xgtest = xgb.DMatrix(final_test)\n",
    "    model_full = xgb.train(plst, xgtrain, num_rounds)\n",
    "    pred_finaltest = model_full.predict(xgtest)\n",
    "    predictions_final[col] = np.argmax(pred_finaltest.reshape( final_test.shape[0], 3 ), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_final['ID'] = test['ID']\n",
    "predictions_final.to_csv('data/xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
